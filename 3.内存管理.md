内存管理
===================================

计算机体系结构
===================================
![计算机体系机构](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.计算机体系结构.png)

* CPU：对程序的执行的控制
* 内存：放置程序的代码和数据
* 外设：键盘、鼠标、显示器等，完成各种功能

内存的层次结构
===================================
![内存的层次结构](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.内存的层次结构.png)

* 从上到下:处理器(包括cpu寄存器和一二级缓存),主存,磁盘
* 从上到下,容量逐步增大,速度逐步变慢.
* 处理器:CPU直接访问，操作系统不能对其进行直接管理，但速度很快，容量很少
* 主存(物理内存):放置操作系统本身和运行的代码和数据.容量比cache和寄存器大，速度慢些.
* 磁盘:内存有时候不够大，需要把一些数据放在磁盘里（虚拟内存），并且把一些需要永久保存的数据（断电后也能保存下来）放在磁盘里.

内存管理的目标
================================
* 抽象

希望应用程序在运行中不需要考虑一些物理细节，只需访问一个连续的地址空间，我们称之为逻辑地址空间。

* 保护

多个应用程序可能会因为某些原因去访问其他进程的空间，会破坏其他进程的空间。因此需要一个有效的机制去对他们的各自空间进行隔离、保护。

* 共享

进程之间可能需要交互，通过提供共享空间，让进程之间可以安全、可靠、有效地进行数据的传递。

* 虚拟化

当内存不够的时候，为了让应用程序有足够空间运行，把最需要放在内存的数据放在内存中，暂时不需要的数据可以临时放在硬盘上，通过这个方法可以实现一个大的内存，这个过程对应用程序是透明的，程序看到的都是逻辑地址空间。

* 内存管理需要的技术
	* 程序重定位
	* 分页
	* 分段
	* 虚拟内存
	* 按需分页虚拟内存

虚拟内存
==================================

![虚拟内存](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.虚拟内存.png)

如上图:

主存的容量不能完全都能容下这四个程序.
所以执行的时候,我们把优先级最低的p4放到磁盘中

MMU:内存管理单元,硬件组件负责处理cpu的内存访问请求

地址空间
=================================
* 物理地址空间

和硬件直接对应，如内存条所代表的主存，和硬盘。物理空间的管理由硬件完成。

* 逻辑地址空间

一个运行的程序能看到的地址空间，是个一维的线性的地址空间。

* 物理地址空间和逻辑地址空间的对应

![物理地址空间和逻辑地址空间的对应](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.物理地址空间和逻辑地址空间的对应.png)

把物理内存抽象成一个一维的地址空间,方便用户访问.

可以理解为逻辑地址空间是对物理地址空间的映射.任何地址空间最终都是落实到物理地址空间.

地址空间的生成
---------------------------------------------

![地址空间的生成](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.地址空间的生成.png)

以C代码程序为例：

首先，将代码编译，成为汇编程序。在C代码中，程序，变量的地址其实就是逻辑地址。

汇编语言很多变量还是通过变量名来表示的。通过汇编器转化为机器语言（.o文件），机器语言中，起始地址都是从0开始，并且变量名和函数名都被转化为地址。

Linker将多个.o程序链接为单个可执行的程序（.exe），存放在硬盘中。这个程序的地址已经是全局的分布了，不同的.o程序中变量的地址都已经在单一的程序中有相应的定义。

Loader将硬盘中的可执行程序放在内存中的相应位置，此时将逻辑地址进行相应的分配，使得应用程序在内存中可以正常运行。程序在内存中存在一个偏移量，可以通过偏移量和逻辑地址，可以对程序进行正确的访问和指令的操作。

上面那些转化过程基本不需要操作系统的介入，只需编译器、linker、loader的配合即可完成。

地址空间映射流程
--------------------------------------------

![地址空间映射流程](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.地址空间映射流程.png)

CPU中有个MMU，MMU完成从逻辑地址到物理地址的映射（上图中蓝色块）。

流程：

（1）当CPU要执行指令时，ALU向MMU发出请求，带有逻辑地址；

（2）MMU查找逻辑地址的映射表中是否存在对应的物理地址。如果没有，在内存中找

如果找到了，CPU的控制器对主存发出请求。

（3）主存把内容通过指令传给CPU，CPU拿到指令的内容后开始执行。

操作系统在这期间的角色是，在执行指令之前，要把映射表建立好。

地址安全检查
-------------------------------------

每个程序都有自己的内存使用范围,在使用内存之前需要对范围进行检查,当使用超出范围会出内存异常的错误.

连续内存分配
==================================

内存碎片
---------------------------------
* 内存碎片:空闲的不能被使用的内存
* 外部碎片:在分配单元间未使用的内存
* 内部碎片:在分配单元中未使用的内存

分许连续内存空间
---------------------------------
* 三个简单的分配策略
	* 首次适配:对空闲块列表按照地址进行排序,寻找第一个合适的分区. 
		* 在重分配过程中检查是够有空闲分区能够和相邻的空闲分区合并成更大的空闲块.
		* 优点:简单,易于产生更大的空闲块
		* 劣势:存在外部碎片,并且容易不停加剧.
	* 最优适配:对空闲快列表按照大小排序,寻找一个合适的分区.
		* 重分配的时候需要搜索和合并相邻的空闲分区。
		* 优点:当大部分分配是小尺寸的时候非常有效
		* 劣势:同样无法克服外部碎片。重分配慢（因为空闲块列表是按照大小排列，而不是按照地址排列）。容易产生很多没用的微小碎片。
	* 最差适配:对空闲列表按照大小排序,寻找合适的最大的分区.
		* 重分配需要合并相邻的空间分区。
		* 优点:分配中等尺寸的效果最好.
		* 劣势:重分配慢,外部碎片易于破碎，以致大分区无法被分配.
		
碎片整理
------------------------------------
* 压缩式碎片整理
	
![压缩式碎片整理](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.压缩式碎片整理.png)
	
将在不同区域的碎片,整理到一起.
	
将程序的归并在一次.要求程序是可以动态重置的,通过拷贝来完成地址重定位.

需要在程序空闲阶段来完成拷贝,开销大,容易产生错误.

* 交换式碎片整理

如果压缩碎片后依旧放不下新到来的程序怎么办?

把主存中的一些暂时用不到的程序交换到磁盘中,为新到来的程序腾出内存空间.

如果交换的程序较大,时间开销很大.
	
非连续内存分配
==========================
为什么需要非连续内存分配
------------------------
* 连续内存分配的缺点:内存利用率低,存在内碎片和外碎片的问题.
* 非连续内存分配:分配给程序的物理地址空间是非连续的.
	* 优点:更好的内存利用和管理,允许共享代码与数据,支持动态加载和动态链接
	* 缺点:带来额外的管理开销(建立虚拟地址和物理地址的映射表)

分段
-----------------------
* 计算机的程序其实是由各种各样的段组成的,不同的段之间有不同的属性.

	比如:主程序,子程序,各种库等.数据有栈段,堆段,共享数据段等.
	
	相当于一个程序所拥有内存的抽象.
	
* 所谓分段,就是根据应用程序不同段的特点,将他们区别出来,分离管理.

如图:

![进行分段的逻辑地址空间](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.进行分段的逻辑地址空间.png)

上图是逻辑地址空间,所有地址段都是属于同一个程序,对于逻辑地址来说还是一个连续的一维地址.

![分段](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.分段.png)

如图所示,逻辑地址空间是连续的,通过一些特定方法,把各种段分离出来,它们位于不同的区域.分开的段的物理地址空间并不是像逻辑地址空间那样是连续的,而是分离的.我们需要通过分段技术支持来完成相应的映射.

![分段逻辑地址和物理地址的关系](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.分段逻辑地址和物理地址的关系.png)

分段的管理机制可以通过软件来实现,也可以用硬件来实现.软件实现的开销非常大,所以要考虑如何用硬件实现.

分段寻址
------------------------
* 逻辑地址结构
	
	逻辑地址是一维的,把一维的地址分成两部分,一部分是段号,一部分是段内偏移量.
	
	![分段逻辑地址结构](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.分段逻辑地址结构.png)
	
	逻辑地址存储可以通过:段寄存器+地址寄存器,单地址两种方案实现.前者只不过是将段号和偏移量记录在不同的寄存器中.

* 分段寻址过程

![分段寻址过程](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.分段寻址过程.png)

1. 当cpu执行某条命令的时候,需要进行寻址(找数据或代码)时,cpu得到的是一个逻辑地址.
2. cpu将逻辑地址按照段号和段内偏移量分开.
3. 通过段号来访问段表获取所对应物理内存的起始地址.
	* 段表是段的逻辑地址和物理地址的映射
	* 因为每个段大小是不一样的,而且有不同的段的长度限制.这个也保存在段表中.
4. 通过访问段表获取段的物理地址的起始位置和结束位置.
5. 对逻辑地址通过MMU转化成物理地址.段起始物理地址 + 偏移量 = 物理地址
6. 用物理地址和4得到的段的内存边界进行比对,如果超出则报出内存异常.不超出则正常访问.

分页
--------------------------------
* 分段机制现在用的比较少,绝大部分计算机都用的是分页机制.
* 分页机制跟分段类似,也需要一个页号和页内偏移量.
* 分页跟分段的一个最大区别是,页的大小是不变的.
* 地址结构
	* 划分物理内存至固定大小的是帧(frame),大小是2的幂.
	* 划分逻辑内存至固定大小的是页(page),大小是2的幂
	* 关联:通过页表和MMU/TLB把逻辑地址转化为物理地址(page to frame)

### 帧(frame)

![帧的计算](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.帧的计算.png)

### 页(page)

![页的结构](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.页的结构.png)

页的计算方式跟帧的一致,每页的大小和页内偏移量跟帧是一致的,但是也好跟物理地址对应的帧号可能不一样,通过页表或TLB完成映射.

### 页的寻址

![页寻址机制](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.页寻址机制.png)

跟前边分段方法一样,首先CPU获取逻辑地址.逻辑地址分为两块,一块表示页号,一块表示页内偏移地址.中间有一个映射表-页表,页表的索引就是页号,内容是帧号.可以通过页号找到对应的帧号,帧号再加上偏移号就得到了物理地址,然后通过物理地址就能找到对应的内存空间.

页表是由操作系统建立的,操作系统在初始化的时候,enable分页机制的时候就建立好了.

页寻址的好处在于,页内偏移量和帧内偏移量是一致的,页跟帧的大小也是一致的,这样就不用像段寻址那样还要去判断段内偏移是否合法,方便实现和地址转换.

逻辑地址是个连续的空间,但通过页寻址,映射到的物理空间就不是连续的了,分散在不同的帧中,有助于减少碎片.

## 页表

页表其实就是个大数组.索引是页号,索引所对应的页表项存放的就是帧号.

![页表结构](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.页表结构.png)

页表的每一项还会有一些标志位(Flags),用来说明这个页面的一些性质.如上图

* dirty bit,是页面是否被修改的标志.当处理器对一个页面执行写操作时,就会设置对应页表项的D标志,处理器不会修改页目录中的D标志.
* resisdent bit,表示这个页是否已经被占用.1,表示页对应的帧存在.0,表示页对应的帧不存在.
* clock/reference bit,表示这个页是否被锁和引用.

### 地址转换实例

![地址转换实例](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.地址转换实例.png)

首先看逻辑地址(4,0),首先通过页号4找到页表相应的项(从下往上数,从0开始).然后找到对应的位置,标志位为100,中间的resident bit为0,表示这个页在物理内存中不存在对应的帧,此时返回一个异常.

再看(3,1023),通过页号3找到页表对应的项,标志位为011,中间的resident bit为1,存在对应的帧号,然后查看后边的帧号为00100 = 4,对应物理空间位置为(4,1023)找到物理内存地址.

### 分页机制的性能问题
* 页表可能非常大.

	比如,一个64位的机器如果每页1024字节,那么一个页表的大小会是多少?
	
	页表会有 2^64/1024 = 2^54项,这实在太大了.
	
	也就是说,一个较大的逻辑地址空间,会导致页表本身变得特别大.
	
* 每个应用都要维护一个页表,更加消耗空间.
* 页表特别大,没法放到CPU里,只能放在内存中.每次访问一个内存单元需要2次的内存访问:一次用于获取页表项,一次用于访问数据,开销大.

如何解决?一般来说,大部分的计算问题都是通过缓存(将一些最常用的数据缓存到离CPU更近的地方)来解决的,页表过大通过间接页表来解决.

### 转换后备缓冲区(TLB)

前面内容提到的CPU中的内存管理单元,有Translation Lock-aside Buffer(TLB):转换后备缓冲区,缓冲的是页表的内容.TLB是CPU内部特殊的一块区域.TLB表是K-V形式.

![TLB](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.TLB.png)

TLB是一种相关存储器实现的,是一种快速查询存储器,可以并发的查找,但是实现的代价很大,所以容量是有限的.可以把当前经常访问的页表项放在TLB中.K为逻辑地址,V为物理地址.当CPU得到逻辑地址的时候,先去查TLB,当查找到的时候,就可以快速的访问到响应的物理地址.当TLB里查找不到的时候,只能去页表里查.如果页表里有对应项的存在位为1,就讲那一项取回来放在TLB里,这样最常用的就会留在TLB中.

TLB可以让寻址的时候开销得到极大的降低.

### 二级/多级页表

TLB提高了页表访问的速度,多级页表换件了页表占据太多空间的问题.

将逻辑地址的页号分成多个部分,如下图,分成一节页表的页号p1和二级页表的页号p2,使得对一个大地址范围的寻址拆分为对几个小的页表的寻址.

![二级页表](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.二级页表.png)

为什么说二级/多级页表可以节省空间?

* 如果一级页表中的一个分页是空的,那么相应的二级页表就根本不会存在,这代表着一种巨大的潜在的节约.而单级页表必须全部保存.
* 只有一级页表才总是在主存中,虚拟存储器系统可以在需要时创建,页面调入或调出二级页表,这样就减少了主存的压力.只有最经常使用的二级页表才需要缓存在主存中,这种离散的存储方式是非常便利的.这就是多级页表的一个根本性的优点:可以离散存储.(单级页表为了岁间访问必须连续存储,如果虚拟内存空间很大,就需要很多页表项,就需要很大的连续内存空间,但是多级页表不需要).

如果是32位机(地址线是32位,也就是4G的线性地址空间),页的大小一般为4kb,则页表有2^32/4k = 2^20个表项.地址的高20位当做页表地址,低12位当做页偏移量.如果页表的每项大小为4B,则需要4MB的RAM来存储页表,即使进程并不会使用所有的地址.

问题来了,所有操作系统课程都会告诉你,使用多级页表可以减少每个进程的页表所需内存.为什么节省了呢?从你最终要存储的表项来看,无论如何你存储的表项是不会少的(都需要那么多内存),而且多级页表还会增加存储开销呢.

其实是这样的,二级页表只是从进程的角度来看,为进程节省了页表项(其实所有页表存储空间增大了).二级模式通过只为进程实际使用的那些虚拟内存区请求页表来减少页表.就是进程未使用的页暂时可以不为其建立页表,因为如果使用一级页表的话,你就必须为所有的4G范围内分配页表,不能细分的话,每个活动进程必须有一个分配给他的页目录,不过没必要马上为进程的所有页表都分配RAM,只有在进程实际需要一个页表时才给页表分配,这样提高了效率.

但是随之而来的是加载次级页表以及多次访问带来的开销变大,同时以为着以时间效益换取空间效益.两者不能兼得.

下面是多级页表,类似树形.

![多级页表](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.多级页表.png)

## 反向页表

* 随着程序越来越大,逻辑地址空间的增长速度远快于物理地址空间.
* 反向页表要解决的是大地址空间的问题,不是让页表与逻辑地址空间的大小相对应,而是让页表与物理地址空间的大小相对应.
* 反向页表跟前相映射表的映射关系相反,以物理页号(帧)作为索引来查找对应的逻辑页页号.

### 基于页寄存器(page registers)的方案

页寄存器中存放跟页表一样的数组,但是寄存器索引是帧号,并不是页号.值是页号,页表的值是帧号.相同的是都有一个值的有效信息位.

![页寄存器反向页表](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.页寄存器反向页表.png)


使用页寄存器的最大问题是,如何根据页号来找到对应的帧号.

![页寄存器空间实例](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.页寄存器空间实例.png)

上图可以看到,反向页表可以有效的节省页表所占的内存空间.

此方案的优缺点

* 优点
	* 转换表的大小相对于物理内存来说很小
	* 转换表的大小跟逻辑地址空间的大小无关
* 缺点
	* 信息对调,通过帧号找页号带来的额外开销,需要在所有值中搜索想要的页号.

### 基于关联内存(associative memory)的方案

![关联内存反向页表](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.关联内存反向页表.png)

基于关联内存的方案实际跟基于页寄存器方案相同,只不过是在反向页表的存储形式上有区分.

关联存储器是一种特殊的存储器,实现它的硬件很复杂,开销很大.所以他的容量无法做的很大.

![关联内存使用](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.关联内存使用.png)

由于容量难以扩充,所以不是很实用.

### 基于哈希(hash)查找方案

将查找通过哈希表来实现,这样就可以直接在反向页表中通过页号来查询帧号了.

![哈希表查找方案](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.哈希表查找方案.png)

![哈希表查找过程](https://github.com/zzhangyuhang/operating-system/blob/master/photo/3.哈希表查找过程.png)

无论有多少个进程，反向页表在内存中只需要一个，不需要像正向实现那样，每个进程都要有一个页表。不过需要处理,页哈希函数冲突的情况.
	
	